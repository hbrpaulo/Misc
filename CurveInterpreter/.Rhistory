values = rep(1, 24)
fig <- plot_ly(values=values,
colors = rep('white', 24),
textinfo='label',
insidetextorientation='radial',
labels=labels
)
fig %>% add_pie(hole = 0.6)
fig <- plot_ly(values=values,
color = rep('white', 24),
textinfo='label',
insidetextorientation='radial',
labels=labels
)
fig %>% add_pie(hole = 0.6)
#library(plotly)
labels = c(0, rev(1:23))
values = rep(1, 24)
fig <- plot_ly(values=values,
fill = rep('white', 24),
textinfo='label',
insidetextorientation='radial',
labels=labels
)
fig %>% add_pie(hole = 0.6)
fig <- plot_ly(values=values,
fill = 'white',
textinfo='label',
insidetextorientation='radial',
labels=labels
)
fig %>% add_pie(hole = 0.6)
fig <- plot_ly(values=values,
textinfo='label',
insidetextorientation='radial',
labels=labels
)
fig %>% add_pie(hole = 0.6)
fig <- plot_ly(values=values,
textinfo='label',
insidetextorientation='radial',
marker = list(colors = labels),
labels=labels
)
fig %>% add_pie(hole = 0.6)
cores = 'white'
fig <- plot_ly(values=values,
textinfo='label',
insidetextorientation='radial',
marker = list(colors = cores),
labels=labels
)
fig %>% add_pie(hole = 0.6)
cores = rep('white', 24)
fig <- plot_ly(values=values,
textinfo='label',
insidetextorientation='radial',
marker = list(colors = cores),
labels=labels
)
fig %>% add_pie(hole = 0.6)
cores = rep(c('white', 'gray85'), 12)
fig <- plot_ly(values=values,
textinfo='label',
insidetextorientation='radial',
marker = list(colors = cores),
labels=labels
)
fig %>% add_pie(hole = 0.6)
fig %>% add_pie(hole = 0.4)
fig %>% add_pie(hole = 0.5)
cores
#library(plotly)
labels = c(0, rev(1:23))
values = rep(1, 24)
cores = rep(c('white', 'gray'), 12)
fig <- plot_ly(values=values,
textinfo='label',
insidetextorientation='radial',
marker = list(colors = cores),
labels=labels
)
fig %>% add_pie(hole = 0.5)
diagram <- mermaid('graph TD
Begin(CurveInterpreter) --> RefDummy(Há referência?)
RefDummy --> AnInd(Sem<br>referência)
AnInd --> NoRef(Análise<br>individual)
RefDummy --> Ref(Com<br>referência)
Ref -->RefPont(Com referência<br>pontual)
Ref --> RefInt(Com referência<br>intervalar)
NoRef --> Trend(Tendência)
RefPont --> Trend1(Tendência)
RefInt --> Trend2(Tendência)
Trend --> TrendG(Tendência<br>global.)
Trend --> TrendF(Tendência<br>frag.)
Trend1 --> TrendG1(Tendência<br>global.)
Trend1 --> TrendF1(Tendência<br>frag.)
Trend2 --> TrendG2(Tendência<br>global.)
Trend2 --> TrendF2(Tendência<br>frag.)
NoRef --> Saz(Sazonalidade)
RefPont --> Saz1(Sazonalidade)
RefInt --> Saz2(Sazonalidade)
Saz --> SazG(Sazonalidade<br>global)
Saz --> SazF(Sazonalidade<br>frag.)
Saz1 --> SazG1(Sazonalidade<br>global)
Saz1 --> SazF1(Sazonalidade<br>frag.)
Saz2 --> SazG2(Sazonalidade<br>global)
Saz2 --> SazF2(Sazonalidade<br>frag.)
%% Specfics aspects
RefInt --> Outsiders(Pontos fora<br>do intervalo)
Outsiders --> Count_out(Contagem<br>Porcentagem)
Outsiders --> Seq_out(Sequenciais)
%% Comparisons
TrendG --> Comp[Comparações<br>entre as partes]
TrendF --> Comp
SazG --> Comp
SazF --> Comp
%%Comparações<br>entre as partes
TrendG1 --> Dist1[Distância entre<br>curva e a referência]
TrendF1 --> Dist1
SazG1 --> Dist1
SazF1 --> Dist1
TrendG2 --> Dist2[Distância entre<br>curva e a referência]
TrendF2 --> Dist2
SazG2 --> Dist2
SazF2 --> Dist2
Seq_out --> Dist2
Count_out --> Dist2
Dist1 --> Comp1[Comparações<br>entre as partes]
Dist2 --> Comp2[Comparações<br>entre as partes]
%% Aesthetics
style RefDummy fill:#2BD72F
style NoRef fill:#2BD72F
style AnInd fill:#2BD72F
style Ref fill:#2BD72F
style RefPont fill:#2BD72F
style RefInt fill:#2BD72F
style SazG fill:#2BD72F
style SazG1 fill:#2BD72F
style SazG2 fill:#2BD72F
style SazF fill:#EEA35D
style SazF1 fill:#EEA35D
style SazF2 fill:#EEA35D
style TrendG fill:#2BD72F
style TrendG1 fill:#2BD72F
style TrendG2 fill:#2BD72F
style TrendF fill:#2BD72F
style TrendF1 fill:#2BD72F
style TrendF2 fill:#2BD72F
style Trend fill:#2BD72F
style Trend1 fill:#2BD72F
style Trend2 fill:#2BD72F
style Comp fill:#FFFFFF
style Comp1 fill:#FFFFFF
style Comp2 fill:#FFFFFF
style Dist1 fill:#FFFFFF
style Dist2 fill:#FFFFFF
')
diagram
if (!exists("database")) {
# Parameters for the series
n <- 20  # Number of observations per cycle
m <- 30  # Number of cycles
# Initialize the database
database <- tibble(data_series = numeric(n * m))
# Generate the seasonal data series
database$data_series <-
sapply(
1:m,
FUN = function(x) {
seasonality <- (1:n) / 2  # Create a seasonal pattern
runif(n, 0, n / 5) + seasonality  # Add random noise to the seasonal pattern
}
) %>% as.vector()
}
# Function to calculate the trend direction and p-value
trend_direction_pvalue <- function(x) {
aux <- aTSA::trend.test(x)  # Perform trend test
return(list(
pvalue = aux$p.value,  # Extract p-value
direction = ifelse(aux$alternative == 'data have a decreasing trend',
'decreasing',
'increasing')  # Determine trend direction
))
}
# Trend metrics calculations
results$metrics$trend$global <- trend_direction_pvalue(database$data_series)  # Overall trend for the entire series
results$metrics$trend$global
# Function to calculate the trend direction and p-value
trend_direction_pvalue <- function(x) {
aux <- aTSA::trend.test(x)  # Perform trend test
return(list(
pvalue = aux$p.value,  # Extract p-value
direction = ifelse(aux$alternative == 'data have a decreasing trend',
'decrescente',
'crescente')  # Determine trend direction
))
}
# Trend metrics calculations
results$metrics$trend$global <- trend_direction_pvalue(database$data_series)  # Overall trend for the entire series
results$metrics$trend$begin <- trend_direction_pvalue(database[database$part == 'beginning', ]$data_series)  # Trend for the beginning part
results$metrics$trend$middle <- trend_direction_pvalue(database[database$part == 'middle', ]$data_series)  # Trend for the middle part
results$metrics$trend$end <- trend_direction_pvalue(database[database$part == 'end', ]$data_series)  # Trend for the end part
# Plot the trend decomposition using STL (Seasonal-Trend decomposition using Loess)
plot(
stl(ts(database$data_series, frequency = 10), s.window = 'periodic')[["time.series"]][, 2],
main = str_wrap('Trend Decomposition', width = 35),  # Title for the plot
xlab = 'Observations',  # X-axis label
ylab = 'Trend'  # Y-axis label
)
results$metrics$trend$global$direcao
results$metrics$trend$global
results$metrics$trend$end$direction
install.packages(c("sf", "terra"))
season_possibilities
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE,
warning = FALSE,
message = FALSE,
knitr.svg.object = TRUE,
out.width='40%',
fig.align = 'center')
options(digits = 2)
# Chunk 2
set.seed(13796163)
library(tidyverse)
library(DiagrammeR)
#plot(x)
alpha <- .5
results <- list()
theme_set(theme_classic())
if(!exists('DocumentType')){
DocumentType <- 0
}
# Chunk 3: cronograma
source('Misc/diagrama.R')
diagram
# Chunk 4
source('https://raw.githubusercontent.com/hbrpaulo/Misc/refs/heads/main/format_sig.R')
source('Misc/example_creation.R')
source('scripts/distances_calculator.R')
source('scripts/fragmentation.R')
# Chunk 5
#database <- fragmentation(distances_calculator(example1))
source('scripts/tests/seasonalities_test.R')
season_possibilities
season_significance
season_significance <- season_possibilities %>%
select(freq, significance) %>%
group_by(significance) %>%
summarise(signif_equivalents = paste(freq, collapse = ', '))
season_significance
rm(database)
# Create a cyclical series database if it doesn't exist
if (!exists("database")) {
# Parameters for the series
n <- 20  # Number of observations per cycle
m <- 30  # Number of cycles
# Initialize the database
example1 <- tibble(data_series = numeric(n * m))
# Generate the seasonal data series
example1$data_series <-
sapply(
1:m,
FUN = function(x) {
seasonality <- (1:n) / 2  # Create a seasonal pattern
runif(n, 0, n / 5) + seasonality  # Add random noise to the seasonal pattern
}
) %>% as.vector()
database <- fragmentation(example1)
}
# Function to find the variance between cycles for a given frequency
variance_between_cycles <- function(x, freq) {
x <- as.vector(x)
aux <-
try(matrix(x, ncol = freq, byrow = TRUE), silent = TRUE)  # Reshape data into cycles
vars <-
apply(aux, 2, var)  # Calculate variance for each cycle's iteration
return(mean(vars))  # Return the average variance across cycles
}
seasonality_finder <- function(data = database,
n_min = 7, n_centers = 2){
# n_min: Minimum number of elements in each cycle to consider
# Create a data frame to store frequencies and their corresponding variances
aux <- tibble(
freq = n_min:(length(data$data_series) / 3),
# Frequency range
vars = sapply(
n_min:(length(data$data_series) / 3),
FUN = function(f) {
# Calculate variance for each frequency
variance_between_cycles(data$data_series, freq = f)
}
)
)
# Apply k-means clustering to group frequencies based on variance
divide_groups <- kmeans(aux$vars, centers = n_centers)
aux$group <- divide_groups$cluster
# Plot the variance against frequencies, color-coded by group
plot(
aux$freq,
xlab = 'Frequency',
aux$vars,
ylab = "Within Variance",
type = "l",
main = str_wrap("Variance Between Cycles for Each Frequency", width = 35)
)
points(
x = aux$freq,
y = aux$vars,
col = aux$group,
pch = 19
)
# Identify the group with the lowest variance
aux <-
aux[aux$group == which.min(divide_groups$centers),] %>%
arrange(vars) %>%
slice(1:5) %>%  # Select the five lowest variances
select(-group) %>%
mutate(test = "KW-R",# Specify the test used
pvalue = NA)
return(aux)
}
season_possibilities <- seasonality_finder()
j <- 1
for (i in season_possibilities$freq) {
season_possibilities$pvalue[j] <-
seastests::combined_test(ts(database$data_series,
frequency = i), freq = i)$Pval["KW-R p-value"]
j <- j + 1
}
# Find combinations of frequencies that are multiples of one another
season_combinations <- t(combn(season_possibilities$freq, 2))
colnames(season_combinations)[1:2] <- c("freq1", "freq2")
season_combinations <- data.frame(
season_combinations,
has_equivalence = apply(
FUN = function(x) {
ratio <- x[1] / x[2]
return(ceiling(ratio) == floor(ratio))  # Check if freq1 is a multiple of freq2
},
MARGIN = 1,
X = season_combinations
)
) %>%
filter(has_equivalence == TRUE) %>%
janitor::clean_names()  # Clean column names
# Add equivalence results to the season_possibilities data frame
season_possibilities$has_equivalence <-
season_possibilities$freq %in% c(season_combinations$freq1, season_combinations$freq2)
# Plot the p-values of the seasonality test for each frequency
plot(
x = 7:(length(database$data_series) / 3),
y = sapply(7:(length(
database$data_series
) / 3),
function(f) {
seastests::kw(ts(database$data_series,
frequency = f), freq = f)$Pval
}),
type = "o",
pch = 19,
ylab = "P-value",
xlab = 'Frequency',
main = str_wrap("P-value of the Seasonality test KW for Each Frequency", width = 35)
)
season_possibilities <- season_possibilities %>% arrange(freq)
season_possibilities <- season_possibilities %>%
add_row(freq = 7, vars = 2, test = 'w', pvalue = .05, has_equivalence = FALSE) %>%
add_row(freq = 13, vars = 2, test = 'w', pvalue = .1, has_equivalence = FALSE) %>%
add_row(freq = 17, vars = 2, test = 'w', pvalue = 1, has_equivalence = FALSE) %>%
mutate(significance = case_when(pvalue <= alpha/2  ~ "Altamente significativas",
pvalue <= alpha ~ "Significativas",
pvalue <= alpha*2 ~ "Alguma significância",
.default = 'Não significativa'))
season_significance
season_possibilities
alpha
#plot(x)
alpha <- .05
# Create a cyclical series database if it doesn't exist
if (!exists("database")) {
# Parameters for the series
n <- 20  # Number of observations per cycle
m <- 30  # Number of cycles
# Initialize the database
example1 <- tibble(data_series = numeric(n * m))
# Generate the seasonal data series
example1$data_series <-
sapply(
1:m,
FUN = function(x) {
seasonality <- (1:n) / 2  # Create a seasonal pattern
runif(n, 0, n / 5) + seasonality  # Add random noise to the seasonal pattern
}
) %>% as.vector()
database <- fragmentation(example1)
}
# Function to find the variance between cycles for a given frequency
variance_between_cycles <- function(x, freq) {
x <- as.vector(x)
aux <-
try(matrix(x, ncol = freq, byrow = TRUE), silent = TRUE)  # Reshape data into cycles
vars <-
apply(aux, 2, var)  # Calculate variance for each cycle's iteration
return(mean(vars))  # Return the average variance across cycles
}
seasonality_finder <- function(data = database,
n_min = 7, n_centers = 2){
# n_min: Minimum number of elements in each cycle to consider
# Create a data frame to store frequencies and their corresponding variances
aux <- tibble(
freq = n_min:(length(data$data_series) / 3),
# Frequency range
vars = sapply(
n_min:(length(data$data_series) / 3),
FUN = function(f) {
# Calculate variance for each frequency
variance_between_cycles(data$data_series, freq = f)
}
)
)
# Apply k-means clustering to group frequencies based on variance
divide_groups <- kmeans(aux$vars, centers = n_centers)
aux$group <- divide_groups$cluster
# Plot the variance against frequencies, color-coded by group
plot(
aux$freq,
xlab = 'Frequency',
aux$vars,
ylab = "Within Variance",
type = "l",
main = str_wrap("Variance Between Cycles for Each Frequency", width = 35)
)
points(
x = aux$freq,
y = aux$vars,
col = aux$group,
pch = 19
)
# Identify the group with the lowest variance
aux <-
aux[aux$group == which.min(divide_groups$centers),] %>%
arrange(vars) %>%
slice(1:5) %>%  # Select the five lowest variances
select(-group) %>%
mutate(test = "KW-R",# Specify the test used
pvalue = NA)
return(aux)
}
season_possibilities <- seasonality_finder()
j <- 1
for (i in season_possibilities$freq) {
season_possibilities$pvalue[j] <-
seastests::combined_test(ts(database$data_series,
frequency = i), freq = i)$Pval["KW-R p-value"]
j <- j + 1
}
# Find combinations of frequencies that are multiples of one another
season_combinations <- t(combn(season_possibilities$freq, 2))
colnames(season_combinations)[1:2] <- c("freq1", "freq2")
season_combinations <- data.frame(
season_combinations,
has_equivalence = apply(
FUN = function(x) {
ratio <- x[1] / x[2]
return(ceiling(ratio) == floor(ratio))  # Check if freq1 is a multiple of freq2
},
MARGIN = 1,
X = season_combinations
)
) %>%
filter(has_equivalence == TRUE) %>%
janitor::clean_names()  # Clean column names
# Add equivalence results to the season_possibilities data frame
season_possibilities$has_equivalence <-
season_possibilities$freq %in% c(season_combinations$freq1, season_combinations$freq2)
# Plot the p-values of the seasonality test for each frequency
plot(
x = 7:(length(database$data_series) / 3),
y = sapply(7:(length(
database$data_series
) / 3),
function(f) {
seastests::kw(ts(database$data_series,
frequency = f), freq = f)$Pval
}),
type = "o",
pch = 19,
ylab = "P-value",
xlab = 'Frequency',
main = str_wrap("P-value of the Seasonality test KW for Each Frequency", width = 35)
)
season_possibilities <- season_possibilities %>% arrange(freq)
season_possibilities <- season_possibilities %>%
add_row(freq = 7, vars = 2, test = 'w', pvalue = .05, has_equivalence = FALSE) %>%
add_row(freq = 13, vars = 2, test = 'w', pvalue = .1, has_equivalence = FALSE) %>%
add_row(freq = 17, vars = 2, test = 'w', pvalue = 1, has_equivalence = FALSE) %>%
mutate(significance = case_when(pvalue <= alpha/2  ~ "Altamente significativas",
pvalue <= alpha ~ "Significativas",
pvalue <= alpha*2 ~ "Alguma significância",
.default = 'Não significativa'))
season_significance
alpha
alpha*2
season_possibilities
season_significance
season_significance <- season_possibilities %>%
select(freq, significance) %>%
group_by(significance) %>%
summarise(signif_equivalents = paste(freq, collapse = ', '))
season_significance
